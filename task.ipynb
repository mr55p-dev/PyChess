{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from keras.layers import Dense, MaxPooling2D, Flatten, Conv2D\n",
    "from Chess.view import view_board_colour\n",
    "from Chess.state import Board, construct_board\n",
    "from Chess.constants import WHITE, BLACK\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks\n",
    "def new_tensorboard_run():\n",
    "    logdir = os.path.join(\"tensorboard_logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    return tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic sequential model\n",
    "\n",
    "We will begin training a basic fully-connected network specified with Keras. This is primarily meant as a test and to define some useful functions (such as those for visualising our outputs). We will start by preprocessing, then defining a model, training and evaluating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation\n",
    "The script `generate_data.py` will open a list of PGN (portable game notation) chess games and run through them, getting from it some state during the game. This state contains information on the location, type and colour of the pieces as well as the legal moves in the position. However, it does not have any information on the strength of those moves, meaning we can only predict the *legal* moves and not rank them.\n",
    "\n",
    "The games which are generated are saved in a `txt` file as FEN (Forsyth-Edwards Notation) strings, which encapsulate all the information needed to recreate a position in chess. We can use these strings to reconstruct the boards and gain access to the information we need. \n",
    "\n",
    "The current file being used was obtained from Lichess and is a set of ~121,000 games played online over the course of 2013. They are a mixture of classical, blitz and bullet games played at a variety of different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generated_data/lichess_db_standard_rated_2013-01.txt\", 'r') as f:\n",
    "    all_boards = f.readlines()\n",
    "    \n",
    "# Take a random sample from boards to reduce the training time\n",
    "idx = np.random.randint(0, len(all_boards), 5000)\n",
    "all_boards = np.array(all_boards)\n",
    "boards = all_boards[idx]\n",
    "\n",
    "board_list = [construct_board(i) for i in boards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black to move - turn 9\n",
      "\u001b[48;5;71m\u001b[38;5;255;48;5;0m R \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m\u001b[38;5;255;48;5;0m B \u001b[0m\u001b[0m\u001b[48;5;250m\u001b[38;5;255;48;5;0m Q \u001b[0m\u001b[0m\u001b[48;5;71m\u001b[38;5;255;48;5;0m K \u001b[0m\u001b[0m\u001b[48;5;250m\u001b[38;5;255;48;5;0m B \u001b[0m\u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m\u001b[38;5;0;48;5;255m Q \u001b[0m\u001b[0m\n",
      "\u001b[48;5;250m\u001b[38;5;255;48;5;0m P \u001b[0m\u001b[0m\u001b[48;5;71m\u001b[38;5;255;48;5;0m P \u001b[0m\u001b[0m\u001b[48;5;250m\u001b[38;5;255;48;5;0m P \u001b[0m\u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m\u001b[38;5;255;48;5;0m P \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m\u001b[38;5;255;48;5;0m P \u001b[0m\u001b[0m\n",
      "\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m\u001b[38;5;255;48;5;0m N \u001b[0m\u001b[0m\u001b[48;5;71m\u001b[38;5;255;48;5;0m P \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\n",
      "\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m\u001b[38;5;0;48;5;255m P \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m\u001b[38;5;0;48;5;255m B \u001b[0m\u001b[0m\u001b[48;5;71m   \u001b[0m\n",
      "\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m\u001b[38;5;255;48;5;0m P \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m\u001b[38;5;0;48;5;255m P \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\n",
      "\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\n",
      "\u001b[48;5;71m\u001b[38;5;0;48;5;255m P \u001b[0m\u001b[0m\u001b[48;5;250m\u001b[38;5;0;48;5;255m P \u001b[0m\u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m\u001b[38;5;0;48;5;255m P \u001b[0m\u001b[0m\u001b[48;5;71m\u001b[38;5;0;48;5;255m P \u001b[0m\u001b[0m\u001b[48;5;250m\u001b[38;5;0;48;5;255m P \u001b[0m\u001b[0m\n",
      "\u001b[48;5;250m\u001b[38;5;0;48;5;255m R \u001b[0m\u001b[0m\u001b[48;5;71m\u001b[38;5;0;48;5;255m N \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m   \u001b[0m\u001b[48;5;250m\u001b[38;5;0;48;5;255m K \u001b[0m\u001b[0m\u001b[48;5;71m\u001b[38;5;0;48;5;255m B \u001b[0m\u001b[0m\u001b[48;5;250m   \u001b[0m\u001b[48;5;71m\u001b[38;5;0;48;5;255m R \u001b[0m\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# An example of what one of these positions looks like\n",
    "view_board_colour(board_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Now the data needs to be formed into a reasonable type for training. This section will get all the positions which can be moved to as a list for each game, and all the positions of the pieces for each board as training data. Initally, this won't account for the piece type, which side is to move, or the different types of pieces and moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses set notation to get only unique moves\n",
    "valid_move_list = [list({i for i in board.moves.all_valid}) for board in board_list] \n",
    "\n",
    "# Get all the piece types and positions from the location map of each board (training data)\n",
    "piece_position_list = [{position: piece.kind for position, piece in board.loc_map.items()} for board in board_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the location of any piece as a 1, and all other positions as 0\n",
    "feature = []\n",
    "for instance in piece_position_list:\n",
    "    array = np.zeros((8, 8))\n",
    "    for location in instance:\n",
    "        array[location.i, location.j] = 1\n",
    "    feature.append(array.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the valid \"destination\" squares with a 1 and invalid with a 0\n",
    "target = []\n",
    "for instance in valid_move_list:\n",
    "    array = np.zeros((8, 8))\n",
    "    for location in instance:\n",
    "        array[location.i, location.j] = 1\n",
    "    target.append(array.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feature)\n",
    "Y = np.array(target)\n",
    "\n",
    "# Split the data using sklearn train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 64)\n",
      "(4000, 64)\n",
      "(1000, 64)\n",
      "(1000, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning with a simple sequential model, which takes in a 1x64 array of features and outputs a prediction at each of the 64 squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFModel():\n",
    "    def __init__(self, name, n_epochs=200, batch_size=50, loss='binary_crossentropy', optimizer='adam'):\n",
    "        self.name = name\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_func = loss\n",
    "        self.optimizer = optimizer\n",
    "        logdir = os.path.join(\"tensorboard_logs\", self.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        self.tb_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(\n",
    "            loss=self.loss_func,\n",
    "            optimizer=self.optimizer,\n",
    "            metrics=[\"accuracy\", \"binary_accuracy\"]\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def summary(self):\n",
    "        return self.model.summary\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        return self.model.fit(\n",
    "            X, \n",
    "            Y, \n",
    "            epochs=self.n_epochs, \n",
    "            batch_size=self.batch_size, \n",
    "            callbacks=[self.tb_callback]\n",
    "        )\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        self.model.evaluate(\n",
    "            X, \n",
    "            Y, \n",
    "            callbacks=[self.tb_callback]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                16448     \n",
      "=================================================================\n",
      "Total params: 57,792\n",
      "Trainable params: 57,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:20:03.135560: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 20:20:03.135568: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 20:20:03.135820: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model = TFModel(\"fully_connected\")\n",
    "fully_connected_model.model = model\n",
    "fully_connected_model.compile()\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/80 [===>..........................] - ETA: 0s - loss: 0.2111 - accuracy: 0.0680 - binary_accuracy: 0.9154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:20:04.317377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-13 20:20:04.417998: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 20:20:04.418008: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 20:20:04.444595: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 20:20:04.445036: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-12-13 20:20:04.445820: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04\n",
      "2021-12-13 20:20:04.446303: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04/Elliss-MacBook-Air.local.trace.json.gz\n",
      "2021-12-13 20:20:04.446703: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04\n",
      "2021-12-13 20:20:04.446863: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04/Elliss-MacBook-Air.local.memory_profile.json.gz\n",
      "2021-12-13 20:20:04.447499: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04Dumped tool data for xplane.pb to tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04/Elliss-MacBook-Air.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04/Elliss-MacBook-Air.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04/Elliss-MacBook-Air.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04/Elliss-MacBook-Air.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to tensorboard_logs/fully_connected_20211213-202003/train/plugins/profile/2021_12_13_20_20_04/Elliss-MacBook-Air.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2095 - accuracy: 0.0766 - binary_accuracy: 0.9167\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2038 - accuracy: 0.0887 - binary_accuracy: 0.9206\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2039 - accuracy: 0.0787 - binary_accuracy: 0.9200\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2018 - accuracy: 0.0843 - binary_accuracy: 0.9222\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1997 - accuracy: 0.0894 - binary_accuracy: 0.9226\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2010 - accuracy: 0.0873 - binary_accuracy: 0.9209\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2020 - accuracy: 0.0859 - binary_accuracy: 0.9207\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1992 - accuracy: 0.0799 - binary_accuracy: 0.9224\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.0880 - binary_accuracy: 0.9224\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2006 - accuracy: 0.0930 - binary_accuracy: 0.9215\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2005 - accuracy: 0.0863 - binary_accuracy: 0.9216\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1991 - accuracy: 0.0851 - binary_accuracy: 0.9217\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1984 - accuracy: 0.0888 - binary_accuracy: 0.9227\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.0848 - binary_accuracy: 0.9224\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1977 - accuracy: 0.0901 - binary_accuracy: 0.9235\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1965 - accuracy: 0.0850 - binary_accuracy: 0.9227\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1957 - accuracy: 0.0840 - binary_accuracy: 0.9239\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1951 - accuracy: 0.0805 - binary_accuracy: 0.9240\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1947 - accuracy: 0.0892 - binary_accuracy: 0.9236\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1995 - accuracy: 0.0844 - binary_accuracy: 0.9218\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1948 - accuracy: 0.0890 - binary_accuracy: 0.9245\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1940 - accuracy: 0.0851 - binary_accuracy: 0.9254\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1950 - accuracy: 0.0870 - binary_accuracy: 0.9236\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1924 - accuracy: 0.0904 - binary_accuracy: 0.9255\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1933 - accuracy: 0.0875 - binary_accuracy: 0.9255\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1935 - accuracy: 0.0885 - binary_accuracy: 0.9246\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1921 - accuracy: 0.0918 - binary_accuracy: 0.9253\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1900 - accuracy: 0.0919 - binary_accuracy: 0.9271\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1906 - accuracy: 0.0965 - binary_accuracy: 0.9260\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1911 - accuracy: 0.0903 - binary_accuracy: 0.9256\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1912 - accuracy: 0.0863 - binary_accuracy: 0.9260\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1911 - accuracy: 0.0885 - binary_accuracy: 0.9254\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1892 - accuracy: 0.1008 - binary_accuracy: 0.9266\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.1875 - accuracy: 0.0903 - binary_accuracy: 0.9278\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1895 - accuracy: 0.0821 - binary_accuracy: 0.9266\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1873 - accuracy: 0.0834 - binary_accuracy: 0.9275\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1869 - accuracy: 0.0929 - binary_accuracy: 0.9282\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1907 - accuracy: 0.0840 - binary_accuracy: 0.9264\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1851 - accuracy: 0.0904 - binary_accuracy: 0.9291\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1871 - accuracy: 0.0921 - binary_accuracy: 0.9278\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1860 - accuracy: 0.1010 - binary_accuracy: 0.9277\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1862 - accuracy: 0.0918 - binary_accuracy: 0.9279\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1881 - accuracy: 0.0897 - binary_accuracy: 0.9259\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1826 - accuracy: 0.0951 - binary_accuracy: 0.9296\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1853 - accuracy: 0.0938 - binary_accuracy: 0.9287\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1844 - accuracy: 0.0924 - binary_accuracy: 0.9287\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1871 - accuracy: 0.0919 - binary_accuracy: 0.9280\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1822 - accuracy: 0.0908 - binary_accuracy: 0.9303\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1831 - accuracy: 0.0886 - binary_accuracy: 0.9300\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1832 - accuracy: 0.0940 - binary_accuracy: 0.9298\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1813 - accuracy: 0.0896 - binary_accuracy: 0.9304\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1833 - accuracy: 0.0875 - binary_accuracy: 0.9287\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1819 - accuracy: 0.0914 - binary_accuracy: 0.9301\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1793 - accuracy: 0.0911 - binary_accuracy: 0.9312\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1815 - accuracy: 0.0874 - binary_accuracy: 0.9300\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1820 - accuracy: 0.0958 - binary_accuracy: 0.9302\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1802 - accuracy: 0.0953 - binary_accuracy: 0.9304\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1786 - accuracy: 0.1013 - binary_accuracy: 0.9314\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1814 - accuracy: 0.0987 - binary_accuracy: 0.9300\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1789 - accuracy: 0.0957 - binary_accuracy: 0.9305\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1786 - accuracy: 0.0853 - binary_accuracy: 0.9316\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1799 - accuracy: 0.0932 - binary_accuracy: 0.9313\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1797 - accuracy: 0.0880 - binary_accuracy: 0.9300\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1774 - accuracy: 0.0925 - binary_accuracy: 0.9315\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1764 - accuracy: 0.0905 - binary_accuracy: 0.9316\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1769 - accuracy: 0.0836 - binary_accuracy: 0.9319\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1770 - accuracy: 0.0972 - binary_accuracy: 0.9313\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1764 - accuracy: 0.0909 - binary_accuracy: 0.9323\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1770 - accuracy: 0.0977 - binary_accuracy: 0.9313\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.1015 - binary_accuracy: 0.9325\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1739 - accuracy: 0.0900 - binary_accuracy: 0.9332\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1746 - accuracy: 0.0859 - binary_accuracy: 0.9328\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.1729 - accuracy: 0.0880 - binary_accuracy: 0.9342\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1748 - accuracy: 0.0968 - binary_accuracy: 0.9333\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1746 - accuracy: 0.0921 - binary_accuracy: 0.9336\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.0884 - binary_accuracy: 0.9330\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.0919 - binary_accuracy: 0.9337\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1716 - accuracy: 0.1004 - binary_accuracy: 0.9345\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1731 - accuracy: 0.0924 - binary_accuracy: 0.9329\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1751 - accuracy: 0.0986 - binary_accuracy: 0.9321\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1708 - accuracy: 0.0913 - binary_accuracy: 0.9346\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1703 - accuracy: 0.0935 - binary_accuracy: 0.9350\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1714 - accuracy: 0.0919 - binary_accuracy: 0.9348\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1705 - accuracy: 0.1044 - binary_accuracy: 0.9346\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1723 - accuracy: 0.0973 - binary_accuracy: 0.9339\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1675 - accuracy: 0.0818 - binary_accuracy: 0.9358\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.1682 - accuracy: 0.0984 - binary_accuracy: 0.9355\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.1704 - accuracy: 0.0954 - binary_accuracy: 0.9344\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.1688 - accuracy: 0.0907 - binary_accuracy: 0.9352\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1687 - accuracy: 0.0944 - binary_accuracy: 0.9356\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1701 - accuracy: 0.0915 - binary_accuracy: 0.9349\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1679 - accuracy: 0.0959 - binary_accuracy: 0.9354\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1663 - accuracy: 0.0987 - binary_accuracy: 0.9367\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1667 - accuracy: 0.0992 - binary_accuracy: 0.9359\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1676 - accuracy: 0.0900 - binary_accuracy: 0.9356\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1681 - accuracy: 0.0930 - binary_accuracy: 0.9353\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1682 - accuracy: 0.0982 - binary_accuracy: 0.9353\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1668 - accuracy: 0.0989 - binary_accuracy: 0.9368\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1668 - accuracy: 0.0929 - binary_accuracy: 0.9363\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1661 - accuracy: 0.0911 - binary_accuracy: 0.9368\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1644 - accuracy: 0.0948 - binary_accuracy: 0.9376\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1671 - accuracy: 0.0875 - binary_accuracy: 0.9350\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1629 - accuracy: 0.0927 - binary_accuracy: 0.9378\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1639 - accuracy: 0.1051 - binary_accuracy: 0.9383\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1635 - accuracy: 0.1022 - binary_accuracy: 0.9374\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1624 - accuracy: 0.0942 - binary_accuracy: 0.9385\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1657 - accuracy: 0.1015 - binary_accuracy: 0.9362\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1618 - accuracy: 0.0997 - binary_accuracy: 0.9390\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1629 - accuracy: 0.0988 - binary_accuracy: 0.9384\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1664 - accuracy: 0.0907 - binary_accuracy: 0.9363\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1630 - accuracy: 0.0983 - binary_accuracy: 0.9381\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1609 - accuracy: 0.0988 - binary_accuracy: 0.9395\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1610 - accuracy: 0.1068 - binary_accuracy: 0.9393\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1623 - accuracy: 0.0933 - binary_accuracy: 0.9382\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1617 - accuracy: 0.0933 - binary_accuracy: 0.9381\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1599 - accuracy: 0.0963 - binary_accuracy: 0.9393\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.1060 - binary_accuracy: 0.9397\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1595 - accuracy: 0.0987 - binary_accuracy: 0.9398\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1588 - accuracy: 0.0968 - binary_accuracy: 0.9391\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1575 - accuracy: 0.1011 - binary_accuracy: 0.9409\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1622 - accuracy: 0.0977 - binary_accuracy: 0.9379\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1603 - accuracy: 0.0902 - binary_accuracy: 0.9396\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1584 - accuracy: 0.0871 - binary_accuracy: 0.9396\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1587 - accuracy: 0.0963 - binary_accuracy: 0.9392\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1571 - accuracy: 0.0941 - binary_accuracy: 0.9407\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1580 - accuracy: 0.1013 - binary_accuracy: 0.9398\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1585 - accuracy: 0.0979 - binary_accuracy: 0.9402\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1582 - accuracy: 0.0901 - binary_accuracy: 0.9398\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1577 - accuracy: 0.1023 - binary_accuracy: 0.9402\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1560 - accuracy: 0.0983 - binary_accuracy: 0.9401\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1554 - accuracy: 0.0957 - binary_accuracy: 0.9410\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1582 - accuracy: 0.0892 - binary_accuracy: 0.9398\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1566 - accuracy: 0.0978 - binary_accuracy: 0.9410\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1564 - accuracy: 0.0968 - binary_accuracy: 0.9405\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1593 - accuracy: 0.1059 - binary_accuracy: 0.9404\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1556 - accuracy: 0.1032 - binary_accuracy: 0.9421\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1565 - accuracy: 0.1011 - binary_accuracy: 0.9411\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1537 - accuracy: 0.0958 - binary_accuracy: 0.9418\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1569 - accuracy: 0.0942 - binary_accuracy: 0.9409\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1534 - accuracy: 0.0943 - binary_accuracy: 0.9413\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1540 - accuracy: 0.1000 - binary_accuracy: 0.9414\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1542 - accuracy: 0.0946 - binary_accuracy: 0.9419\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1564 - accuracy: 0.0893 - binary_accuracy: 0.9400\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1534 - accuracy: 0.0959 - binary_accuracy: 0.9419\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1503 - accuracy: 0.1017 - binary_accuracy: 0.9435\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1516 - accuracy: 0.0910 - binary_accuracy: 0.9418\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1541 - accuracy: 0.0938 - binary_accuracy: 0.9412\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1523 - accuracy: 0.0882 - binary_accuracy: 0.9434\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1503 - accuracy: 0.1082 - binary_accuracy: 0.9435\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1522 - accuracy: 0.0947 - binary_accuracy: 0.9426\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1511 - accuracy: 0.1011 - binary_accuracy: 0.9431\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1513 - accuracy: 0.0992 - binary_accuracy: 0.9431\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1516 - accuracy: 0.0950 - binary_accuracy: 0.9431\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1470 - accuracy: 0.1027 - binary_accuracy: 0.9450\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1489 - accuracy: 0.0892 - binary_accuracy: 0.9432\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1492 - accuracy: 0.0930 - binary_accuracy: 0.9436\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1494 - accuracy: 0.0997 - binary_accuracy: 0.9438\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1477 - accuracy: 0.1023 - binary_accuracy: 0.9441\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1493 - accuracy: 0.0971 - binary_accuracy: 0.9437\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1464 - accuracy: 0.1069 - binary_accuracy: 0.9452\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1482 - accuracy: 0.0996 - binary_accuracy: 0.9443\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1526 - accuracy: 0.1016 - binary_accuracy: 0.9407\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1458 - accuracy: 0.1049 - binary_accuracy: 0.9452\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1470 - accuracy: 0.0985 - binary_accuracy: 0.9449\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1484 - accuracy: 0.0946 - binary_accuracy: 0.9440\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1455 - accuracy: 0.1048 - binary_accuracy: 0.9442\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1488 - accuracy: 0.0941 - binary_accuracy: 0.9432\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1469 - accuracy: 0.0950 - binary_accuracy: 0.9445\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1468 - accuracy: 0.0953 - binary_accuracy: 0.9444\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1470 - accuracy: 0.1029 - binary_accuracy: 0.9449\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1451 - accuracy: 0.1066 - binary_accuracy: 0.9456\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1462 - accuracy: 0.0942 - binary_accuracy: 0.9448\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1455 - accuracy: 0.0968 - binary_accuracy: 0.9452\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1447 - accuracy: 0.0982 - binary_accuracy: 0.9457\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1453 - accuracy: 0.0910 - binary_accuracy: 0.9462\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1440 - accuracy: 0.1120 - binary_accuracy: 0.9458\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1447 - accuracy: 0.0956 - binary_accuracy: 0.9454\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1461 - accuracy: 0.0969 - binary_accuracy: 0.9445\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1447 - accuracy: 0.0981 - binary_accuracy: 0.9460\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1440 - accuracy: 0.1017 - binary_accuracy: 0.9457\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1430 - accuracy: 0.0937 - binary_accuracy: 0.9462\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1432 - accuracy: 0.0991 - binary_accuracy: 0.9461\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1448 - accuracy: 0.1026 - binary_accuracy: 0.9458\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1443 - accuracy: 0.1000 - binary_accuracy: 0.9456\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1436 - accuracy: 0.1022 - binary_accuracy: 0.9466\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1421 - accuracy: 0.0997 - binary_accuracy: 0.9473\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1426 - accuracy: 0.1054 - binary_accuracy: 0.9464\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.0973 - binary_accuracy: 0.9476\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1410 - accuracy: 0.0993 - binary_accuracy: 0.9475\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1425 - accuracy: 0.0990 - binary_accuracy: 0.9468\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1414 - accuracy: 0.1038 - binary_accuracy: 0.9471\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1418 - accuracy: 0.0986 - binary_accuracy: 0.9465\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1404 - accuracy: 0.1027 - binary_accuracy: 0.9467\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1403 - accuracy: 0.1050 - binary_accuracy: 0.9476\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1394 - accuracy: 0.1047 - binary_accuracy: 0.9478\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1402 - accuracy: 0.1043 - binary_accuracy: 0.9476\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.1393 - accuracy: 0.1015 - binary_accuracy: 0.9475\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1402 - accuracy: 0.1011 - binary_accuracy: 0.9476\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1409 - accuracy: 0.1024 - binary_accuracy: 0.9467\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.1386 - accuracy: 0.0985 - binary_accuracy: 0.9486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b5bba5b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_connected_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/32 [==============>...............] - ETA: 0s - loss: 1.4804 - accuracy: 0.0371 - binary_accuracy: 0.7126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:21:58.375146: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4836 - accuracy: 0.0370 - binary_accuracy: 0.7117\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple sequential model to demonstrate how this data can be used with a neural network\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(128, input_dim=64, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                16448     \n",
      "=================================================================\n",
      "Total params: 57,792\n",
      "Trainable params: 57,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", \"binary_accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, Y):\n",
    "    loss, accuracy, binary_accuracy = model.evaluate(X_test, Y_test)\n",
    "    print(f\"Loss: {loss}\\nBinary accuracy: {binary_accuracy}\")\n",
    "    return loss, accuracy, binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_model(model, X, Y, n_epochs=50, batch_size=50):\n",
    "    tensorboard_callback = new_tensorboard_run()\n",
    "    model.fit(\n",
    "        X, \n",
    "        Y, \n",
    "        epochs=200, \n",
    "        batch_size=50,\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 60458), started 0:09:23 ago. (Use '!kill 60458' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fe9a34b8218aa3e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fe9a34b8218aa3e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tensorboard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:03:11.680878: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 20:03:11.680897: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 20:03:11.684323: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 3/80 [>.............................] - ETA: 2s - loss: 0.7074 - accuracy: 0.0122 - binary_accuracy: 0.4803 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:03:12.196320: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-13 20:03:12.308744: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 20:03:12.308755: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 20:03:12.352273: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 20:03:12.352725: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-12-13 20:03:12.353454: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12\n",
      "2021-12-13 20:03:12.353923: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12/Elliss-MacBook-Air.local.trace.json.gz\n",
      "2021-12-13 20:03:12.354303: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12\n",
      "2021-12-13 20:03:12.354428: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12/Elliss-MacBook-Air.local.memory_profile.json.gz\n",
      "2021-12-13 20:03:12.354829: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12Dumped tool data for xplane.pb to tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12/Elliss-MacBook-Air.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12/Elliss-MacBook-Air.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12/Elliss-MacBook-Air.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12/Elliss-MacBook-Air.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to tensorboard_logs/20211213-200311/train/plugins/profile/2021_12_13_20_03_12/Elliss-MacBook-Air.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 7ms/step - loss: 0.6295 - accuracy: 0.0085 - binary_accuracy: 0.6512\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.0069 - binary_accuracy: 0.7189\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.0119 - binary_accuracy: 0.7312\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.0151 - binary_accuracy: 0.7415\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.0112 - binary_accuracy: 0.7450\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4900 - accuracy: 0.0154 - binary_accuracy: 0.7516\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.0130 - binary_accuracy: 0.7563\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.0150 - binary_accuracy: 0.7574\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.0166 - binary_accuracy: 0.7601\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.0231 - binary_accuracy: 0.7647\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.0128 - binary_accuracy: 0.7655\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.0195 - binary_accuracy: 0.7687\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.0150 - binary_accuracy: 0.7725\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.0199 - binary_accuracy: 0.7754\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4503 - accuracy: 0.0183 - binary_accuracy: 0.7785\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4464 - accuracy: 0.0190 - binary_accuracy: 0.7809\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4468 - accuracy: 0.0168 - binary_accuracy: 0.7799\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4420 - accuracy: 0.0224 - binary_accuracy: 0.7841\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4373 - accuracy: 0.0204 - binary_accuracy: 0.7872\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4329 - accuracy: 0.0217 - binary_accuracy: 0.7915\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4331 - accuracy: 0.0244 - binary_accuracy: 0.7921\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4308 - accuracy: 0.0274 - binary_accuracy: 0.7925\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4236 - accuracy: 0.0194 - binary_accuracy: 0.7983\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.4223 - accuracy: 0.0280 - binary_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.0234 - binary_accuracy: 0.8022\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4161 - accuracy: 0.0258 - binary_accuracy: 0.8044\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4099 - accuracy: 0.0254 - binary_accuracy: 0.8086\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4057 - accuracy: 0.0272 - binary_accuracy: 0.8116\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4053 - accuracy: 0.0312 - binary_accuracy: 0.8116\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3994 - accuracy: 0.0262 - binary_accuracy: 0.8162\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3941 - accuracy: 0.0314 - binary_accuracy: 0.8199\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3972 - accuracy: 0.0344 - binary_accuracy: 0.8186\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3979 - accuracy: 0.0355 - binary_accuracy: 0.8177\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3895 - accuracy: 0.0324 - binary_accuracy: 0.8239\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3878 - accuracy: 0.0277 - binary_accuracy: 0.8258\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3863 - accuracy: 0.0357 - binary_accuracy: 0.8255\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3856 - accuracy: 0.0340 - binary_accuracy: 0.8262\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.0335 - binary_accuracy: 0.8292\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3779 - accuracy: 0.0411 - binary_accuracy: 0.8311\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.0352 - binary_accuracy: 0.8325\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.0359 - binary_accuracy: 0.8345\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3666 - accuracy: 0.0379 - binary_accuracy: 0.8383\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3668 - accuracy: 0.0380 - binary_accuracy: 0.8385\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3633 - accuracy: 0.0380 - binary_accuracy: 0.8406\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.0354 - binary_accuracy: 0.8416\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.0404 - binary_accuracy: 0.8405\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.0338 - binary_accuracy: 0.8443\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.0345 - binary_accuracy: 0.8443\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.0356 - binary_accuracy: 0.8476\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3511 - accuracy: 0.0375 - binary_accuracy: 0.8478\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3505 - accuracy: 0.0395 - binary_accuracy: 0.8474\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3456 - accuracy: 0.0467 - binary_accuracy: 0.8508\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3476 - accuracy: 0.0431 - binary_accuracy: 0.8498\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3421 - accuracy: 0.0407 - binary_accuracy: 0.8537\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3406 - accuracy: 0.0453 - binary_accuracy: 0.8541\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3384 - accuracy: 0.0480 - binary_accuracy: 0.8549\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3374 - accuracy: 0.0483 - binary_accuracy: 0.8564\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3375 - accuracy: 0.0502 - binary_accuracy: 0.8553\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.0439 - binary_accuracy: 0.8564\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.0520 - binary_accuracy: 0.8591\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.0435 - binary_accuracy: 0.8593\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.0408 - binary_accuracy: 0.8619\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3281 - accuracy: 0.0533 - binary_accuracy: 0.8607\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3267 - accuracy: 0.0442 - binary_accuracy: 0.8607\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3212 - accuracy: 0.0439 - binary_accuracy: 0.8649\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3205 - accuracy: 0.0470 - binary_accuracy: 0.8658\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3209 - accuracy: 0.0476 - binary_accuracy: 0.8643\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3177 - accuracy: 0.0521 - binary_accuracy: 0.8664\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3183 - accuracy: 0.0471 - binary_accuracy: 0.8659\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3187 - accuracy: 0.0479 - binary_accuracy: 0.8660\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3158 - accuracy: 0.0588 - binary_accuracy: 0.8680\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3112 - accuracy: 0.0424 - binary_accuracy: 0.8697\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3130 - accuracy: 0.0473 - binary_accuracy: 0.8693\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3105 - accuracy: 0.0582 - binary_accuracy: 0.8698\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3091 - accuracy: 0.0553 - binary_accuracy: 0.8704\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3060 - accuracy: 0.0547 - binary_accuracy: 0.8723\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3049 - accuracy: 0.0585 - binary_accuracy: 0.8729\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3019 - accuracy: 0.0475 - binary_accuracy: 0.8751\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3021 - accuracy: 0.0494 - binary_accuracy: 0.8745\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3007 - accuracy: 0.0502 - binary_accuracy: 0.8749\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3023 - accuracy: 0.0536 - binary_accuracy: 0.8740\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2993 - accuracy: 0.0477 - binary_accuracy: 0.8761\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2988 - accuracy: 0.0577 - binary_accuracy: 0.8764\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2966 - accuracy: 0.0638 - binary_accuracy: 0.8771\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2963 - accuracy: 0.0595 - binary_accuracy: 0.8772\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2937 - accuracy: 0.0550 - binary_accuracy: 0.8780\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2938 - accuracy: 0.0529 - binary_accuracy: 0.8789\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2891 - accuracy: 0.0503 - binary_accuracy: 0.8822\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2913 - accuracy: 0.0592 - binary_accuracy: 0.8792\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2900 - accuracy: 0.0558 - binary_accuracy: 0.8806\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2900 - accuracy: 0.0565 - binary_accuracy: 0.8801\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2858 - accuracy: 0.0655 - binary_accuracy: 0.8832\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2845 - accuracy: 0.0605 - binary_accuracy: 0.8828\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2887 - accuracy: 0.0498 - binary_accuracy: 0.8812\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2837 - accuracy: 0.0521 - binary_accuracy: 0.8834\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2810 - accuracy: 0.0609 - binary_accuracy: 0.8853\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2811 - accuracy: 0.0565 - binary_accuracy: 0.8848\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2808 - accuracy: 0.0557 - binary_accuracy: 0.8843\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2808 - accuracy: 0.0517 - binary_accuracy: 0.8844\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2793 - accuracy: 0.0557 - binary_accuracy: 0.8843\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2740 - accuracy: 0.0620 - binary_accuracy: 0.8893\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2721 - accuracy: 0.0669 - binary_accuracy: 0.8895\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2737 - accuracy: 0.0657 - binary_accuracy: 0.8883\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.0687 - binary_accuracy: 0.8880\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2712 - accuracy: 0.0659 - binary_accuracy: 0.8897\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2738 - accuracy: 0.0650 - binary_accuracy: 0.8885\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.0584 - binary_accuracy: 0.8892\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2659 - accuracy: 0.0696 - binary_accuracy: 0.8924\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2625 - accuracy: 0.0577 - binary_accuracy: 0.8938\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2652 - accuracy: 0.0662 - binary_accuracy: 0.8925\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2684 - accuracy: 0.0652 - binary_accuracy: 0.8912\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2688 - accuracy: 0.0663 - binary_accuracy: 0.8910\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2636 - accuracy: 0.0654 - binary_accuracy: 0.8930\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2620 - accuracy: 0.0642 - binary_accuracy: 0.8939\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2631 - accuracy: 0.0652 - binary_accuracy: 0.8933\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2605 - accuracy: 0.0625 - binary_accuracy: 0.8943\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2609 - accuracy: 0.0618 - binary_accuracy: 0.8948\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2609 - accuracy: 0.0599 - binary_accuracy: 0.8948\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2581 - accuracy: 0.0626 - binary_accuracy: 0.8956\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2584 - accuracy: 0.0641 - binary_accuracy: 0.8964\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2568 - accuracy: 0.0681 - binary_accuracy: 0.8962\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2556 - accuracy: 0.0643 - binary_accuracy: 0.8973\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2553 - accuracy: 0.0721 - binary_accuracy: 0.8972\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2522 - accuracy: 0.0680 - binary_accuracy: 0.8987\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2510 - accuracy: 0.0668 - binary_accuracy: 0.9001\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2527 - accuracy: 0.0652 - binary_accuracy: 0.8980\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2484 - accuracy: 0.0771 - binary_accuracy: 0.9009\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2538 - accuracy: 0.0717 - binary_accuracy: 0.8988\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2507 - accuracy: 0.0657 - binary_accuracy: 0.8995\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2449 - accuracy: 0.0665 - binary_accuracy: 0.9021\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2483 - accuracy: 0.0687 - binary_accuracy: 0.9005\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2467 - accuracy: 0.0823 - binary_accuracy: 0.9017\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2468 - accuracy: 0.0700 - binary_accuracy: 0.9017\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2456 - accuracy: 0.0682 - binary_accuracy: 0.9030\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2446 - accuracy: 0.0669 - binary_accuracy: 0.9024\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2459 - accuracy: 0.0737 - binary_accuracy: 0.9015\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2410 - accuracy: 0.0699 - binary_accuracy: 0.9034\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2431 - accuracy: 0.0725 - binary_accuracy: 0.9033\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2453 - accuracy: 0.0681 - binary_accuracy: 0.9010\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2400 - accuracy: 0.0721 - binary_accuracy: 0.9039\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2416 - accuracy: 0.0710 - binary_accuracy: 0.9035\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2407 - accuracy: 0.0737 - binary_accuracy: 0.9036\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2397 - accuracy: 0.0703 - binary_accuracy: 0.9052\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2381 - accuracy: 0.0706 - binary_accuracy: 0.9051\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2382 - accuracy: 0.0753 - binary_accuracy: 0.9047\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2377 - accuracy: 0.0643 - binary_accuracy: 0.9047\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2329 - accuracy: 0.0745 - binary_accuracy: 0.9077\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2388 - accuracy: 0.0812 - binary_accuracy: 0.9043\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2350 - accuracy: 0.0748 - binary_accuracy: 0.9075\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2348 - accuracy: 0.0641 - binary_accuracy: 0.9067\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2348 - accuracy: 0.0675 - binary_accuracy: 0.9060\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2341 - accuracy: 0.0667 - binary_accuracy: 0.9068\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2316 - accuracy: 0.0719 - binary_accuracy: 0.9083\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2319 - accuracy: 0.0648 - binary_accuracy: 0.9077\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2321 - accuracy: 0.0653 - binary_accuracy: 0.9078\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2348 - accuracy: 0.0739 - binary_accuracy: 0.9062\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2291 - accuracy: 0.0756 - binary_accuracy: 0.9091\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2279 - accuracy: 0.0749 - binary_accuracy: 0.9099\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2283 - accuracy: 0.0808 - binary_accuracy: 0.9097\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2280 - accuracy: 0.0839 - binary_accuracy: 0.9096\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2269 - accuracy: 0.0671 - binary_accuracy: 0.9103\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2253 - accuracy: 0.0802 - binary_accuracy: 0.9109\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2252 - accuracy: 0.0791 - binary_accuracy: 0.9103\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2240 - accuracy: 0.0779 - binary_accuracy: 0.9113\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2247 - accuracy: 0.0800 - binary_accuracy: 0.9105\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2234 - accuracy: 0.0820 - binary_accuracy: 0.9116\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2203 - accuracy: 0.0819 - binary_accuracy: 0.9138\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2214 - accuracy: 0.0793 - binary_accuracy: 0.9133\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2220 - accuracy: 0.0727 - binary_accuracy: 0.9117\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2203 - accuracy: 0.0768 - binary_accuracy: 0.9135\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2221 - accuracy: 0.0757 - binary_accuracy: 0.9120\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2198 - accuracy: 0.0835 - binary_accuracy: 0.9137\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2209 - accuracy: 0.0804 - binary_accuracy: 0.9135\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2233 - accuracy: 0.0768 - binary_accuracy: 0.9116\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2184 - accuracy: 0.0794 - binary_accuracy: 0.9142\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2162 - accuracy: 0.0783 - binary_accuracy: 0.9148\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2178 - accuracy: 0.0734 - binary_accuracy: 0.9151\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2211 - accuracy: 0.0800 - binary_accuracy: 0.9121\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2155 - accuracy: 0.0745 - binary_accuracy: 0.9157\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2164 - accuracy: 0.0784 - binary_accuracy: 0.9148\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2162 - accuracy: 0.0740 - binary_accuracy: 0.9146\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2167 - accuracy: 0.0900 - binary_accuracy: 0.9140\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2140 - accuracy: 0.0714 - binary_accuracy: 0.9160\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2132 - accuracy: 0.0857 - binary_accuracy: 0.9161\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2128 - accuracy: 0.0814 - binary_accuracy: 0.9163\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2098 - accuracy: 0.0840 - binary_accuracy: 0.9180\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2101 - accuracy: 0.0788 - binary_accuracy: 0.9180\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2101 - accuracy: 0.0820 - binary_accuracy: 0.9171\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2112 - accuracy: 0.0822 - binary_accuracy: 0.9171\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2085 - accuracy: 0.0947 - binary_accuracy: 0.9185\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2091 - accuracy: 0.0800 - binary_accuracy: 0.9179\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2081 - accuracy: 0.0834 - binary_accuracy: 0.9186\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2092 - accuracy: 0.0837 - binary_accuracy: 0.9181\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2088 - accuracy: 0.0707 - binary_accuracy: 0.9179\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2059 - accuracy: 0.0845 - binary_accuracy: 0.9191\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2065 - accuracy: 0.0733 - binary_accuracy: 0.9199\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2049 - accuracy: 0.0736 - binary_accuracy: 0.9205\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2054 - accuracy: 0.0915 - binary_accuracy: 0.9196\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2042 - accuracy: 0.0918 - binary_accuracy: 0.9199\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2060 - accuracy: 0.0878 - binary_accuracy: 0.9194\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/32 [==============>...............] - ETA: 0s - loss: 0.9442 - accuracy: 0.0368 - binary_accuracy: 0.7159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:05:02.504193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9343 - accuracy: 0.0330 - binary_accuracy: 0.7155\n",
      "Loss: 0.934349000453949\n",
      "Binary accuracy: 0.7155312895774841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.934349000453949, 0.032999999821186066, 0.7155312895774841)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the output\n",
    "Now both the raw output of the model and the binarised version can be displayed interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to manipulate the output\n",
    "def predict_val(model, val):\n",
    "    prediction = model.predict(val)\n",
    "    return np.where(prediction > 0.5, 1, 0)\n",
    "\n",
    "def predict_raw(model, val):\n",
    "    return model.predict(val)  \n",
    "\n",
    "def find_diff(y, pred):\n",
    "    Y_instance = y\n",
    "    return np.where(pred == Y_instance, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to draw the labels and predictions.\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.color_palette(\"crest\", as_cmap=True)\n",
    "sns.set_palette(\"crest\")\n",
    "\n",
    "def plot_sns(val):\n",
    "    # From https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "    sns.heatmap(val.reshape(8,8))\n",
    "    plt.show()\n",
    "\n",
    "def plot(val):\n",
    "    cmap = colors.ListedColormap(['white', 'green'])\n",
    "    bounds = [-0.5, 0.5, 1.5]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(val.reshape(8, 8), cmap=cmap, norm=norm)\n",
    "\n",
    "    # draw gridlines\n",
    "    ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=2)\n",
    "    ax.set_xticks(np.arange(0.5, 8.5, 1));\n",
    "    ax.set_yticks(np.arange(0.5, 8.5, 1));\n",
    "    plt.show()\n",
    "\n",
    "def plot_diff(val):\n",
    "    cmap = colors.ListedColormap(['red', 'green'])\n",
    "    bounds = [-0.5, 0.5, 1.5]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(val.reshape(8,8) , cmap=cmap, norm=norm)\n",
    "\n",
    "    # draw gridlines\n",
    "    ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=2)\n",
    "    ax.set_xticks(np.arange(0.5, 8.5, 1));\n",
    "    ax.set_yticks(np.arange(0.5, 8.5, 1));\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plots(\n",
    "            n, \n",
    "            model = None,\n",
    "            x = None,\n",
    "            y = None,\n",
    "            target=True, \n",
    "            prediction=True, \n",
    "            raw_prediction=True, \n",
    "            diff=True\n",
    "        ):\n",
    "    if target:         \n",
    "        plot(y[n].reshape(1, 64))    \n",
    "    if prediction:     \n",
    "        plot(predict_val(model, x[n:n+1]))\n",
    "    if raw_prediction: \n",
    "        plot_sns(predict_raw(model, x[n:n+1]))\n",
    "    if diff:          \n",
    "        pred = predict_val(model, x[n:n+1])\n",
    "        plot_diff(find_diff(y[n:n+1], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ed05bfa64b4f4bb400be5c59f281a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=199, step=5), Checkbox(value=False, description="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.generate_plots(n, model=None, x=None, y=None, target=True, prediction=True, raw_prediction=True, diff=True)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html\n",
    "interact(\n",
    "    generate_plots,\n",
    "    model = fixed(model),\n",
    "    x = fixed(X_test),\n",
    "    y = fixed(Y_test),\n",
    "    n=widgets.IntSlider(min=0, max=199, step=5, value=0),\n",
    "    target=False,\n",
    "    prediction=False,\n",
    "    raw_prediction=False,\n",
    "    diff=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This widget lets us look through the validation set predictions and compare what the model is outputting compared to what the equivilant label is. What we can begin to see from here is that the model does have some predictive power on pieces which do not move great distances up and down the board. However for pieces that can travel the entire diagonal, vertical or horizontal distance of the board (such as rooks, bishops and queens) there is a high margin of error and these motions are rarely predicted at all, indicating they are tough to learn.\n",
    "\n",
    "This may also be indicitve of some bias in the training data - almost every position has pawns which can be moved in it whereas the major pieces are more often closed in and obscured behind other pieces. This imbalance may contribute to not learning how the pieces move properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional design\n",
    "\n",
    "We can also approach this problem with a convolutional network. These are designed for image processing and operate by sliding a kernel over an image, performing a \"convolution\" of the kernel on the data. It is particuarly good at identifying patterns, so let us test this out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation\n",
    "\n",
    "For this model, the data will be separated into two layers; one for all the white pieces and one for the black pieces. The target will remain unchanged and there will still be no distinction between the pieces.\n",
    "\n",
    "To get the data in the correct format, we can construct a $8\\times8\\times2$ numpy array to feed our model. The pieces which are moving will be provided in the 0th index of axis 2 (the array is structured [axis0, axis1, axis2]) and those not moving will be at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_move_list = [list({i for i in board.moves.all_valid}) for board in board_list]\n",
    "\n",
    "conv_position_list = [\n",
    "    (\n",
    "        dict(board.loc_map), \n",
    "        board.to_move\n",
    "    ) \n",
    "    for board in board_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the location of any piece as a 1, and all other positions as 0\n",
    "conv_feature = []\n",
    "for instance in conv_position_list:\n",
    "    # Set up empty array\n",
    "    array = np.zeros((8, 8, 2))\n",
    "    \n",
    "    # Assign white and black to their correct layers\n",
    "    if instance[1] == WHITE:\n",
    "        # White to move\n",
    "        WHITE_LAYER = 1\n",
    "        BLACK_LAYER = 0\n",
    "    else:\n",
    "        # Black to move\n",
    "        BLACK_LAYER = 1\n",
    "        WHITE_LAYER = 0\n",
    "    \n",
    "    # Mark the correct locations in the matrix\n",
    "    for location, piece in instance[0].items():\n",
    "        if piece.colour == WHITE:\n",
    "            array[location.i, location.j, WHITE_LAYER] = 1\n",
    "        else:\n",
    "            array[location.i, location.j, BLACK_LAYER] = 1\n",
    "\n",
    "    conv_feature.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the valid \"destination\" squares with a 1 and invalid with a 0\n",
    "conv_target = []\n",
    "for instance in conv_move_list:\n",
    "    array = np.zeros((8, 8))\n",
    "    for location in instance:\n",
    "        array[location.i, location.j] = 1\n",
    "    conv_target.append(array.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(conv_feature)\n",
    "Y = np.array(conv_target)\n",
    "\n",
    "# Split the data using sklearn train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "\n",
    "Now the data is in a format that contains much more information in a way that convolutional netoworks can process, we can define a convolutional model architecture (again using the Keras sequential API) to verify if this model can perform any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', input_shape=(8, 8, 2)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 6, 6, 8)           152       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 50,920\n",
      "Trainable params: 50,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", \"binary_accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 19:53:49.243623: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 19:53:49.243634: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 19:53:49.244130: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/80 [..............................] - ETA: 1:50 - loss: 0.6935 - accuracy: 0.0400 - binary_accuracy: 0.4937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 19:53:50.536808: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-13 19:53:50.681989: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 19:53:50.682000: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 19:53:50.713677: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 19:53:50.714259: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-12-13 19:53:50.715027: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50\n",
      "2021-12-13 19:53:50.715528: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50/Elliss-MacBook-Air.local.trace.json.gz\n",
      "2021-12-13 19:53:50.716000: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50\n",
      "2021-12-13 19:53:50.716159: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50/Elliss-MacBook-Air.local.memory_profile.json.gz\n",
      "2021-12-13 19:53:50.716605: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50Dumped tool data for xplane.pb to tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50/Elliss-MacBook-Air.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50/Elliss-MacBook-Air.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50/Elliss-MacBook-Air.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50/Elliss-MacBook-Air.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to tensorboard_logs/20211213-195349/train/plugins/profile/2021_12_13_19_53_50/Elliss-MacBook-Air.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 9ms/step - loss: 0.6305 - accuracy: 0.0071 - binary_accuracy: 0.6737\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.5423 - accuracy: 0.0056 - binary_accuracy: 0.7241\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.5263 - accuracy: 0.0042 - binary_accuracy: 0.7364\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.5180 - accuracy: 0.0027 - binary_accuracy: 0.7423\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.5139 - accuracy: 0.0049 - binary_accuracy: 0.7480\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.5046 - accuracy: 0.0091 - binary_accuracy: 0.7538\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4881 - accuracy: 0.0119 - binary_accuracy: 0.7663\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4828 - accuracy: 0.0152 - binary_accuracy: 0.7696\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4748 - accuracy: 0.0120 - binary_accuracy: 0.7739\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4690 - accuracy: 0.0075 - binary_accuracy: 0.7789\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4590 - accuracy: 0.0126 - binary_accuracy: 0.7852\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4560 - accuracy: 0.0169 - binary_accuracy: 0.7853\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4492 - accuracy: 0.0154 - binary_accuracy: 0.7894\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4411 - accuracy: 0.0130 - binary_accuracy: 0.7946\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4413 - accuracy: 0.0127 - binary_accuracy: 0.7945\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4374 - accuracy: 0.0173 - binary_accuracy: 0.7967\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4273 - accuracy: 0.0228 - binary_accuracy: 0.8023\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4274 - accuracy: 0.0186 - binary_accuracy: 0.8026\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4258 - accuracy: 0.0179 - binary_accuracy: 0.8033\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4172 - accuracy: 0.0211 - binary_accuracy: 0.8078\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4162 - accuracy: 0.0211 - binary_accuracy: 0.8085\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4120 - accuracy: 0.0199 - binary_accuracy: 0.8103\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4085 - accuracy: 0.0198 - binary_accuracy: 0.8129\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4065 - accuracy: 0.0192 - binary_accuracy: 0.8122\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4073 - accuracy: 0.0206 - binary_accuracy: 0.8138\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4026 - accuracy: 0.0211 - binary_accuracy: 0.8161\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3979 - accuracy: 0.0217 - binary_accuracy: 0.8192\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3968 - accuracy: 0.0244 - binary_accuracy: 0.8197\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3929 - accuracy: 0.0270 - binary_accuracy: 0.8217\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3909 - accuracy: 0.0292 - binary_accuracy: 0.8209\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3912 - accuracy: 0.0283 - binary_accuracy: 0.8218\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3892 - accuracy: 0.0271 - binary_accuracy: 0.8220\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3908 - accuracy: 0.0315 - binary_accuracy: 0.8218\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.3825 - accuracy: 0.0229 - binary_accuracy: 0.8263\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3859 - accuracy: 0.0299 - binary_accuracy: 0.8232\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3807 - accuracy: 0.0305 - binary_accuracy: 0.8287\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3830 - accuracy: 0.0222 - binary_accuracy: 0.8260\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3825 - accuracy: 0.0278 - binary_accuracy: 0.8257\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3804 - accuracy: 0.0277 - binary_accuracy: 0.8268\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3775 - accuracy: 0.0271 - binary_accuracy: 0.8282\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3739 - accuracy: 0.0274 - binary_accuracy: 0.8303\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3725 - accuracy: 0.0264 - binary_accuracy: 0.8313\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3727 - accuracy: 0.0269 - binary_accuracy: 0.8311\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3691 - accuracy: 0.0293 - binary_accuracy: 0.8330\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3693 - accuracy: 0.0314 - binary_accuracy: 0.8329\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3681 - accuracy: 0.0299 - binary_accuracy: 0.8339\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3676 - accuracy: 0.0373 - binary_accuracy: 0.8341\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3686 - accuracy: 0.0267 - binary_accuracy: 0.8336\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3628 - accuracy: 0.0320 - binary_accuracy: 0.8359\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3652 - accuracy: 0.0314 - binary_accuracy: 0.8345\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3625 - accuracy: 0.0281 - binary_accuracy: 0.8367\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3602 - accuracy: 0.0357 - binary_accuracy: 0.8383\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3590 - accuracy: 0.0303 - binary_accuracy: 0.8373\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3626 - accuracy: 0.0318 - binary_accuracy: 0.8348\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3623 - accuracy: 0.0334 - binary_accuracy: 0.8347\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3572 - accuracy: 0.0282 - binary_accuracy: 0.8383\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3582 - accuracy: 0.0303 - binary_accuracy: 0.8379\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3545 - accuracy: 0.0339 - binary_accuracy: 0.8412\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.3519 - accuracy: 0.0314 - binary_accuracy: 0.8415\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3542 - accuracy: 0.0284 - binary_accuracy: 0.8408\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3511 - accuracy: 0.0295 - binary_accuracy: 0.8421\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3531 - accuracy: 0.0321 - binary_accuracy: 0.8409\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3509 - accuracy: 0.0361 - binary_accuracy: 0.8417\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3512 - accuracy: 0.0279 - binary_accuracy: 0.8423\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3503 - accuracy: 0.0357 - binary_accuracy: 0.8429\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3512 - accuracy: 0.0366 - binary_accuracy: 0.8417\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3482 - accuracy: 0.0303 - binary_accuracy: 0.8438\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3468 - accuracy: 0.0329 - binary_accuracy: 0.8439\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3439 - accuracy: 0.0364 - binary_accuracy: 0.8459\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3462 - accuracy: 0.0320 - binary_accuracy: 0.8453\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3443 - accuracy: 0.0295 - binary_accuracy: 0.8450\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3439 - accuracy: 0.0360 - binary_accuracy: 0.8457\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3417 - accuracy: 0.0295 - binary_accuracy: 0.8454\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3382 - accuracy: 0.0312 - binary_accuracy: 0.8490\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3446 - accuracy: 0.0321 - binary_accuracy: 0.8463\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3426 - accuracy: 0.0342 - binary_accuracy: 0.8465\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3381 - accuracy: 0.0344 - binary_accuracy: 0.8497\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3382 - accuracy: 0.0357 - binary_accuracy: 0.8489\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3386 - accuracy: 0.0354 - binary_accuracy: 0.8482\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.3387 - accuracy: 0.0381 - binary_accuracy: 0.8495\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3398 - accuracy: 0.0353 - binary_accuracy: 0.8483\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3367 - accuracy: 0.0353 - binary_accuracy: 0.8501\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3361 - accuracy: 0.0343 - binary_accuracy: 0.8505\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3354 - accuracy: 0.0392 - binary_accuracy: 0.8505\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3373 - accuracy: 0.0386 - binary_accuracy: 0.8492\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3330 - accuracy: 0.0342 - binary_accuracy: 0.8515\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.0313 - binary_accuracy: 0.8523\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3340 - accuracy: 0.0356 - binary_accuracy: 0.8515\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3293 - accuracy: 0.0317 - binary_accuracy: 0.8532\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3304 - accuracy: 0.0390 - binary_accuracy: 0.8530\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3347 - accuracy: 0.0329 - binary_accuracy: 0.8523\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.0321 - binary_accuracy: 0.8515\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3330 - accuracy: 0.0453 - binary_accuracy: 0.8520\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.0363 - binary_accuracy: 0.8535\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3309 - accuracy: 0.0363 - binary_accuracy: 0.8521\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3323 - accuracy: 0.0394 - binary_accuracy: 0.8531\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3327 - accuracy: 0.0361 - binary_accuracy: 0.8521\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3261 - accuracy: 0.0394 - binary_accuracy: 0.8550\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3287 - accuracy: 0.0350 - binary_accuracy: 0.8544\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3259 - accuracy: 0.0414 - binary_accuracy: 0.8558\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3290 - accuracy: 0.0433 - binary_accuracy: 0.8545\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3251 - accuracy: 0.0386 - binary_accuracy: 0.8562\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3255 - accuracy: 0.0384 - binary_accuracy: 0.8555\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3253 - accuracy: 0.0409 - binary_accuracy: 0.8572\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.3245 - accuracy: 0.0384 - binary_accuracy: 0.8563\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3232 - accuracy: 0.0406 - binary_accuracy: 0.8569\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3231 - accuracy: 0.0386 - binary_accuracy: 0.8568\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.0359 - binary_accuracy: 0.8573\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3237 - accuracy: 0.0342 - binary_accuracy: 0.8564\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3190 - accuracy: 0.0420 - binary_accuracy: 0.8598\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3227 - accuracy: 0.0406 - binary_accuracy: 0.8578\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3317 - accuracy: 0.0380 - binary_accuracy: 0.8524\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3222 - accuracy: 0.0366 - binary_accuracy: 0.8572\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3234 - accuracy: 0.0415 - binary_accuracy: 0.8574\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3221 - accuracy: 0.0408 - binary_accuracy: 0.8577\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3201 - accuracy: 0.0358 - binary_accuracy: 0.8585\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.0391 - binary_accuracy: 0.8574\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3202 - accuracy: 0.0374 - binary_accuracy: 0.8589\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3206 - accuracy: 0.0411 - binary_accuracy: 0.8577\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3189 - accuracy: 0.0350 - binary_accuracy: 0.8594\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3203 - accuracy: 0.0389 - binary_accuracy: 0.8586\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3139 - accuracy: 0.0460 - binary_accuracy: 0.8614\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3209 - accuracy: 0.0418 - binary_accuracy: 0.8580\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3153 - accuracy: 0.0336 - binary_accuracy: 0.8611\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3200 - accuracy: 0.0483 - binary_accuracy: 0.8588\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3186 - accuracy: 0.0397 - binary_accuracy: 0.8594\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3160 - accuracy: 0.0421 - binary_accuracy: 0.8613\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3127 - accuracy: 0.0472 - binary_accuracy: 0.8633\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3152 - accuracy: 0.0372 - binary_accuracy: 0.8607\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3160 - accuracy: 0.0399 - binary_accuracy: 0.8608\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3158 - accuracy: 0.0408 - binary_accuracy: 0.8613\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3170 - accuracy: 0.0393 - binary_accuracy: 0.8605\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3163 - accuracy: 0.0425 - binary_accuracy: 0.8607\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3112 - accuracy: 0.0406 - binary_accuracy: 0.8635\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3127 - accuracy: 0.0440 - binary_accuracy: 0.8624\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3122 - accuracy: 0.0344 - binary_accuracy: 0.8630\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3111 - accuracy: 0.0355 - binary_accuracy: 0.8628\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3146 - accuracy: 0.0364 - binary_accuracy: 0.8612\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3125 - accuracy: 0.0423 - binary_accuracy: 0.8622\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3139 - accuracy: 0.0382 - binary_accuracy: 0.8604\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3119 - accuracy: 0.0362 - binary_accuracy: 0.8626\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3142 - accuracy: 0.0471 - binary_accuracy: 0.8615\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3140 - accuracy: 0.0331 - binary_accuracy: 0.8615\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3156 - accuracy: 0.0392 - binary_accuracy: 0.8607\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3126 - accuracy: 0.0460 - binary_accuracy: 0.8625\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3073 - accuracy: 0.0422 - binary_accuracy: 0.8646\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3128 - accuracy: 0.0378 - binary_accuracy: 0.8617\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3121 - accuracy: 0.0383 - binary_accuracy: 0.8626\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3059 - accuracy: 0.0344 - binary_accuracy: 0.8659\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3094 - accuracy: 0.0418 - binary_accuracy: 0.8643\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3061 - accuracy: 0.0406 - binary_accuracy: 0.8649\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3064 - accuracy: 0.0429 - binary_accuracy: 0.8651\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3138 - accuracy: 0.0441 - binary_accuracy: 0.8621\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3096 - accuracy: 0.0407 - binary_accuracy: 0.8642\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3066 - accuracy: 0.0408 - binary_accuracy: 0.8654\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3047 - accuracy: 0.0402 - binary_accuracy: 0.8659\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3113 - accuracy: 0.0340 - binary_accuracy: 0.8627\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3058 - accuracy: 0.0362 - binary_accuracy: 0.8653\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3028 - accuracy: 0.0442 - binary_accuracy: 0.8671\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3076 - accuracy: 0.0394 - binary_accuracy: 0.8651\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3081 - accuracy: 0.0380 - binary_accuracy: 0.8642\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3097 - accuracy: 0.0464 - binary_accuracy: 0.8639\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3014 - accuracy: 0.0398 - binary_accuracy: 0.8684\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3072 - accuracy: 0.0365 - binary_accuracy: 0.8649\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3044 - accuracy: 0.0369 - binary_accuracy: 0.8677\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3056 - accuracy: 0.0399 - binary_accuracy: 0.8666\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3026 - accuracy: 0.0416 - binary_accuracy: 0.8670\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3039 - accuracy: 0.0410 - binary_accuracy: 0.8675\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3050 - accuracy: 0.0415 - binary_accuracy: 0.8660\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3053 - accuracy: 0.0396 - binary_accuracy: 0.8666\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3042 - accuracy: 0.0410 - binary_accuracy: 0.8669\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3006 - accuracy: 0.0429 - binary_accuracy: 0.8683\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3023 - accuracy: 0.0379 - binary_accuracy: 0.8679\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3046 - accuracy: 0.0445 - binary_accuracy: 0.8659\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3024 - accuracy: 0.0498 - binary_accuracy: 0.8673\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3040 - accuracy: 0.0441 - binary_accuracy: 0.8665\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3025 - accuracy: 0.0422 - binary_accuracy: 0.8670\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3006 - accuracy: 0.0418 - binary_accuracy: 0.8676\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3055 - accuracy: 0.0411 - binary_accuracy: 0.8656\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3091 - accuracy: 0.0432 - binary_accuracy: 0.8631\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3004 - accuracy: 0.0369 - binary_accuracy: 0.8691\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3002 - accuracy: 0.0372 - binary_accuracy: 0.8683\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3024 - accuracy: 0.0373 - binary_accuracy: 0.8673\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3013 - accuracy: 0.0433 - binary_accuracy: 0.8685\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3008 - accuracy: 0.0371 - binary_accuracy: 0.8680\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2974 - accuracy: 0.0399 - binary_accuracy: 0.8699\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3043 - accuracy: 0.0396 - binary_accuracy: 0.8673\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3024 - accuracy: 0.0417 - binary_accuracy: 0.8672\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3027 - accuracy: 0.0404 - binary_accuracy: 0.8679\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3004 - accuracy: 0.0425 - binary_accuracy: 0.8684\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2994 - accuracy: 0.0365 - binary_accuracy: 0.8691\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2971 - accuracy: 0.0388 - binary_accuracy: 0.8703\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3002 - accuracy: 0.0415 - binary_accuracy: 0.8682\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3005 - accuracy: 0.0458 - binary_accuracy: 0.8681\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.2974 - accuracy: 0.0355 - binary_accuracy: 0.8700\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2972 - accuracy: 0.0426 - binary_accuracy: 0.8708\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2985 - accuracy: 0.0393 - binary_accuracy: 0.8692\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2968 - accuracy: 0.0389 - binary_accuracy: 0.8704\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3001 - accuracy: 0.0375 - binary_accuracy: 0.8689\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2995 - accuracy: 0.0418 - binary_accuracy: 0.8686\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/32 [================>.............] - ETA: 0s - loss: 0.4799 - accuracy: 0.0247 - binary_accuracy: 0.7965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 19:56:18.321723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.0250 - binary_accuracy: 0.7938\n",
      "Loss: 0.48936188220977783\n",
      "Binary accuracy: 0.7938281893730164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.48936188220977783, 0.02500000037252903, 0.7938281893730164)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary accuracy of this model does outperform the previous dense network used before, which is a promising result for this technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21782c98cb474061a8fabacac313e7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=199, step=5), Checkbox(value=False, description="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.generate_plots(n, model=None, x=None, y=None, target=True, prediction=True, raw_prediction=True, diff=True)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(\n",
    "    generate_plots,\n",
    "    model = fixed(model),\n",
    "    x = fixed(X_test),\n",
    "    y = fixed(Y_test),\n",
    "    n=widgets.IntSlider(min=0, max=199, step=5, value=0),\n",
    "    target=False,\n",
    "    prediction=False,\n",
    "    raw_prediction=False,\n",
    "    diff=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these modified visualisation functions it is clear that there is greater performance by this model. The added implicit information on which pieces are moving, combined with the use of convolutional filters to properly extract features from the training data. Seeing a jump in binary accuracy as well as in many cases much more confident predictions from the model is indicitive that this approach is superior, due to the convolutional feature extraction layers\n",
    "\n",
    "The behaviour of long range pieces is however still an issue for these systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional network with more layers\n",
    "\n",
    "It is now not unreasonable to think that the networks performance would be increased significantly if it were to be aware of which pieces are at which location; this is after all the most important deciding factor as to how they may move.\n",
    "\n",
    "An approach to integrating this data is the following architecture;\n",
    "- Input data (8 x 8 x 6), where there is one index on axis 2 for each of the five piece types (King, Queen, Rook, Knight, Bishop, Pawn) for the moving pieces, and another for the following\n",
    "- The final layer of the input tensor will contain the position of the pieces which are not to move. Since the information on which type of piece these are is generally less important to predicting the moves, for now this can be left out.\n",
    "- Additionally, passing the fully connected layer some information about whether the position is check for example may increase accuracy some more, since it will be able to tell when certain moves which usually are valid would not be valid. This information needs to reach the fully connected network but is not part of the convolutional network, so for this section the Keras functional API will be more appropriate as it offers more control.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the location of any piece as a 1, and all other positions as 0\n",
    "conv_feature = []\n",
    "piece_index_map = {\n",
    "    'K': 0,\n",
    "    'Q': 1,\n",
    "    'R': 2,\n",
    "    'B': 3,\n",
    "    'N': 4,\n",
    "    'P': 5\n",
    "}\n",
    "for instance in conv_position_list:\n",
    "    # Set up empty array\n",
    "    array = np.zeros((8, 8, 7))\n",
    "    \n",
    "    # Assign white and black to their correct layers\n",
    "    if instance[1] == WHITE:\n",
    "        # White to move\n",
    "        MOVING_COLOUR = 1\n",
    "    else:\n",
    "        # Black to move\n",
    "        MOVING_COLOUR = 0\n",
    "    \n",
    "    # Mark the correct locations in the matrix\n",
    "    for location, piece in instance[0].items():\n",
    "        if piece.colour == MOVING_COLOUR:\n",
    "            array[location.i, location.j, piece_index_map[piece.kind]] = 1\n",
    "        else:\n",
    "            array[location.i, location.j, 6] = 1\n",
    "\n",
    "    conv_feature.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the valid \"destination\" squares with a 1 and invalid with a 0\n",
    "conv_target = []\n",
    "for instance in conv_move_list:\n",
    "    array = np.zeros((8, 8))\n",
    "    for location in instance:\n",
    "        array[location.i, location.j] = 1\n",
    "    conv_target.append(array.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(conv_feature)\n",
    "Y = np.array(conv_target)\n",
    "\n",
    "# Split the data using sklearn train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(8, 8, 7))\n",
    "cnv = Conv2D(10, (3, 3), activation='relu')(inputs)\n",
    "cnv = Conv2D(10, (3, 3), activation='relu')(cnv)\n",
    "cnv = Conv2D(10, (3, 3), activation='relu')(cnv)\n",
    "cnv = Flatten()(cnv)\n",
    "cnv = Dense(256, activation='relu')(cnv)\n",
    "cnv = Dense(128, activation='relu')(cnv)\n",
    "outputs = Dense(64, activation='sigmoid')(cnv)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"ConvNet7l\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvNet7l\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 8, 7)]         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 10)          640       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 10)          910       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 10)          910       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 54,108\n",
      "Trainable params: 54,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", \"binary_accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 19:56:19.189423: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 19:56:19.189433: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 19:56:19.189477: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/80 [..............................] - ETA: 1:01 - loss: 0.6936 - accuracy: 0.0000e+00 - binary_accuracy: 0.4903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 19:56:19.860191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-13 19:56:20.010670: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-12-13 19:56:20.010682: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-12-13 19:56:20.056824: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-12-13 19:56:20.057260: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-12-13 19:56:20.057984: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20\n",
      "2021-12-13 19:56:20.058433: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20/Elliss-MacBook-Air.local.trace.json.gz\n",
      "2021-12-13 19:56:20.058827: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20\n",
      "2021-12-13 19:56:20.058963: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20/Elliss-MacBook-Air.local.memory_profile.json.gz\n",
      "2021-12-13 19:56:20.059374: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20Dumped tool data for xplane.pb to tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20/Elliss-MacBook-Air.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20/Elliss-MacBook-Air.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20/Elliss-MacBook-Air.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20/Elliss-MacBook-Air.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to tensorboard_logs/20211213-195619/train/plugins/profile/2021_12_13_19_56_20/Elliss-MacBook-Air.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 10ms/step - loss: 0.6386 - accuracy: 0.0080 - binary_accuracy: 0.6607\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.5700 - accuracy: 0.0083 - binary_accuracy: 0.7096\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.5310 - accuracy: 0.0026 - binary_accuracy: 0.7320\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.5217 - accuracy: 0.0059 - binary_accuracy: 0.7401\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5142 - accuracy: 0.0038 - binary_accuracy: 0.7442\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5013 - accuracy: 0.0054 - binary_accuracy: 0.7536\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5016 - accuracy: 0.0132 - binary_accuracy: 0.7524\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4911 - accuracy: 0.0220 - binary_accuracy: 0.7590\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4820 - accuracy: 0.0265 - binary_accuracy: 0.7640\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4731 - accuracy: 0.0283 - binary_accuracy: 0.7708\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4659 - accuracy: 0.0245 - binary_accuracy: 0.7751\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4633 - accuracy: 0.0254 - binary_accuracy: 0.7769\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4505 - accuracy: 0.0254 - binary_accuracy: 0.7842\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4472 - accuracy: 0.0254 - binary_accuracy: 0.7885\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4365 - accuracy: 0.0249 - binary_accuracy: 0.7926\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4320 - accuracy: 0.0252 - binary_accuracy: 0.7965\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4280 - accuracy: 0.0258 - binary_accuracy: 0.7992\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4215 - accuracy: 0.0301 - binary_accuracy: 0.8035\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4170 - accuracy: 0.0248 - binary_accuracy: 0.8057\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4112 - accuracy: 0.0241 - binary_accuracy: 0.8096\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4066 - accuracy: 0.0249 - binary_accuracy: 0.8122\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.4028 - accuracy: 0.0237 - binary_accuracy: 0.8148\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4000 - accuracy: 0.0261 - binary_accuracy: 0.8150\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3962 - accuracy: 0.0228 - binary_accuracy: 0.8183\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3894 - accuracy: 0.0223 - binary_accuracy: 0.8220\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3892 - accuracy: 0.0261 - binary_accuracy: 0.8220\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3822 - accuracy: 0.0230 - binary_accuracy: 0.8259\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3829 - accuracy: 0.0236 - binary_accuracy: 0.8257\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3776 - accuracy: 0.0237 - binary_accuracy: 0.8291\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3740 - accuracy: 0.0254 - binary_accuracy: 0.8306\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3710 - accuracy: 0.0266 - binary_accuracy: 0.8321\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3678 - accuracy: 0.0238 - binary_accuracy: 0.8346\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3654 - accuracy: 0.0218 - binary_accuracy: 0.8354\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3672 - accuracy: 0.0273 - binary_accuracy: 0.8349\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3569 - accuracy: 0.0254 - binary_accuracy: 0.8406\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3577 - accuracy: 0.0264 - binary_accuracy: 0.8401\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3551 - accuracy: 0.0223 - binary_accuracy: 0.8411\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3527 - accuracy: 0.0238 - binary_accuracy: 0.8427\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3532 - accuracy: 0.0268 - binary_accuracy: 0.8425\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3495 - accuracy: 0.0296 - binary_accuracy: 0.8447\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3445 - accuracy: 0.0279 - binary_accuracy: 0.8474\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3412 - accuracy: 0.0295 - binary_accuracy: 0.8496\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3460 - accuracy: 0.0267 - binary_accuracy: 0.8460\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3428 - accuracy: 0.0265 - binary_accuracy: 0.8482\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.3353 - accuracy: 0.0272 - binary_accuracy: 0.8530\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3333 - accuracy: 0.0299 - binary_accuracy: 0.8517\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3357 - accuracy: 0.0265 - binary_accuracy: 0.8522\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3355 - accuracy: 0.0257 - binary_accuracy: 0.8522\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3285 - accuracy: 0.0244 - binary_accuracy: 0.8559\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3288 - accuracy: 0.0295 - binary_accuracy: 0.8556\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3267 - accuracy: 0.0278 - binary_accuracy: 0.8568\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3236 - accuracy: 0.0299 - binary_accuracy: 0.8584\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3242 - accuracy: 0.0265 - binary_accuracy: 0.8574\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3225 - accuracy: 0.0298 - binary_accuracy: 0.8583\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3190 - accuracy: 0.0280 - binary_accuracy: 0.8606\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3159 - accuracy: 0.0345 - binary_accuracy: 0.8625\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3164 - accuracy: 0.0331 - binary_accuracy: 0.8615\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3160 - accuracy: 0.0380 - binary_accuracy: 0.8627\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3136 - accuracy: 0.0309 - binary_accuracy: 0.8632\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3102 - accuracy: 0.0356 - binary_accuracy: 0.8657\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3063 - accuracy: 0.0334 - binary_accuracy: 0.8667\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3088 - accuracy: 0.0352 - binary_accuracy: 0.8647\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3087 - accuracy: 0.0353 - binary_accuracy: 0.8656\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3041 - accuracy: 0.0336 - binary_accuracy: 0.8676\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3054 - accuracy: 0.0281 - binary_accuracy: 0.8677\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3040 - accuracy: 0.0299 - binary_accuracy: 0.8674\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3025 - accuracy: 0.0364 - binary_accuracy: 0.8684\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.3012 - accuracy: 0.0344 - binary_accuracy: 0.8687\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.2967 - accuracy: 0.0383 - binary_accuracy: 0.8717\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2987 - accuracy: 0.0340 - binary_accuracy: 0.8704\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2953 - accuracy: 0.0363 - binary_accuracy: 0.8719\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2964 - accuracy: 0.0373 - binary_accuracy: 0.8716\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2910 - accuracy: 0.0390 - binary_accuracy: 0.8739\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2876 - accuracy: 0.0350 - binary_accuracy: 0.8763\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2914 - accuracy: 0.0320 - binary_accuracy: 0.8754\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2908 - accuracy: 0.0286 - binary_accuracy: 0.8742\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2862 - accuracy: 0.0293 - binary_accuracy: 0.8769\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2868 - accuracy: 0.0375 - binary_accuracy: 0.8765\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2884 - accuracy: 0.0340 - binary_accuracy: 0.8758\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2873 - accuracy: 0.0296 - binary_accuracy: 0.8775\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2840 - accuracy: 0.0331 - binary_accuracy: 0.8787\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2848 - accuracy: 0.0336 - binary_accuracy: 0.8768\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2804 - accuracy: 0.0347 - binary_accuracy: 0.8797\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2784 - accuracy: 0.0357 - binary_accuracy: 0.8813\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2752 - accuracy: 0.0389 - binary_accuracy: 0.8821\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2774 - accuracy: 0.0336 - binary_accuracy: 0.8822\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2756 - accuracy: 0.0369 - binary_accuracy: 0.8825\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2741 - accuracy: 0.0341 - binary_accuracy: 0.8827\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2791 - accuracy: 0.0378 - binary_accuracy: 0.8811\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2702 - accuracy: 0.0350 - binary_accuracy: 0.8849\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2723 - accuracy: 0.0388 - binary_accuracy: 0.8835\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2666 - accuracy: 0.0365 - binary_accuracy: 0.8860\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2675 - accuracy: 0.0371 - binary_accuracy: 0.8860\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2687 - accuracy: 0.0371 - binary_accuracy: 0.8859\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2682 - accuracy: 0.0421 - binary_accuracy: 0.8850\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2659 - accuracy: 0.0341 - binary_accuracy: 0.8869\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2617 - accuracy: 0.0414 - binary_accuracy: 0.8898\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2635 - accuracy: 0.0403 - binary_accuracy: 0.8883\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2657 - accuracy: 0.0386 - binary_accuracy: 0.8848\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2596 - accuracy: 0.0358 - binary_accuracy: 0.8899\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2599 - accuracy: 0.0358 - binary_accuracy: 0.8895\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2599 - accuracy: 0.0391 - binary_accuracy: 0.8900\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2594 - accuracy: 0.0367 - binary_accuracy: 0.8910\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2581 - accuracy: 0.0324 - binary_accuracy: 0.8908\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.2548 - accuracy: 0.0396 - binary_accuracy: 0.8923\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.2563 - accuracy: 0.0380 - binary_accuracy: 0.8916\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2539 - accuracy: 0.0465 - binary_accuracy: 0.8927\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2550 - accuracy: 0.0292 - binary_accuracy: 0.8926\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.2522 - accuracy: 0.0404 - binary_accuracy: 0.8934\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.2513 - accuracy: 0.0420 - binary_accuracy: 0.8937\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2521 - accuracy: 0.0408 - binary_accuracy: 0.8934\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2514 - accuracy: 0.0367 - binary_accuracy: 0.8938\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2479 - accuracy: 0.0423 - binary_accuracy: 0.8951\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2503 - accuracy: 0.0358 - binary_accuracy: 0.8943\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2451 - accuracy: 0.0383 - binary_accuracy: 0.8962\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2496 - accuracy: 0.0398 - binary_accuracy: 0.8946\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2464 - accuracy: 0.0425 - binary_accuracy: 0.8960\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2477 - accuracy: 0.0362 - binary_accuracy: 0.8949\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.2453 - accuracy: 0.0355 - binary_accuracy: 0.8962\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2446 - accuracy: 0.0358 - binary_accuracy: 0.8966\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2400 - accuracy: 0.0406 - binary_accuracy: 0.8983\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2385 - accuracy: 0.0456 - binary_accuracy: 0.9002\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2409 - accuracy: 0.0464 - binary_accuracy: 0.8990\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2411 - accuracy: 0.0433 - binary_accuracy: 0.8978\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2410 - accuracy: 0.0365 - binary_accuracy: 0.8986\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2403 - accuracy: 0.0343 - binary_accuracy: 0.8983\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2423 - accuracy: 0.0377 - binary_accuracy: 0.8985\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2350 - accuracy: 0.0384 - binary_accuracy: 0.9013\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2394 - accuracy: 0.0354 - binary_accuracy: 0.8996\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2389 - accuracy: 0.0385 - binary_accuracy: 0.8991\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2362 - accuracy: 0.0402 - binary_accuracy: 0.9012\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2360 - accuracy: 0.0500 - binary_accuracy: 0.9007\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2352 - accuracy: 0.0413 - binary_accuracy: 0.9015\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2318 - accuracy: 0.0400 - binary_accuracy: 0.9030\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2326 - accuracy: 0.0446 - binary_accuracy: 0.9023\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2321 - accuracy: 0.0486 - binary_accuracy: 0.9029\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2281 - accuracy: 0.0415 - binary_accuracy: 0.9037\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2295 - accuracy: 0.0371 - binary_accuracy: 0.9033\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2291 - accuracy: 0.0403 - binary_accuracy: 0.9043\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2307 - accuracy: 0.0444 - binary_accuracy: 0.9039\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2276 - accuracy: 0.0411 - binary_accuracy: 0.9052\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2292 - accuracy: 0.0467 - binary_accuracy: 0.9042\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2283 - accuracy: 0.0410 - binary_accuracy: 0.9048\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2295 - accuracy: 0.0360 - binary_accuracy: 0.9034\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2266 - accuracy: 0.0480 - binary_accuracy: 0.9059\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2236 - accuracy: 0.0443 - binary_accuracy: 0.9067\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2236 - accuracy: 0.0458 - binary_accuracy: 0.9063\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2264 - accuracy: 0.0438 - binary_accuracy: 0.9058\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2228 - accuracy: 0.0456 - binary_accuracy: 0.9072\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2216 - accuracy: 0.0437 - binary_accuracy: 0.9074\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2218 - accuracy: 0.0389 - binary_accuracy: 0.9075\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2233 - accuracy: 0.0496 - binary_accuracy: 0.9064\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2185 - accuracy: 0.0482 - binary_accuracy: 0.9093\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2239 - accuracy: 0.0446 - binary_accuracy: 0.9056\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2228 - accuracy: 0.0364 - binary_accuracy: 0.9064\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2200 - accuracy: 0.0454 - binary_accuracy: 0.9086\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2198 - accuracy: 0.0403 - binary_accuracy: 0.9079\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2203 - accuracy: 0.0455 - binary_accuracy: 0.9083\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2159 - accuracy: 0.0473 - binary_accuracy: 0.9099\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2172 - accuracy: 0.0444 - binary_accuracy: 0.9099\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2162 - accuracy: 0.0483 - binary_accuracy: 0.9096\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2155 - accuracy: 0.0475 - binary_accuracy: 0.9102\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2146 - accuracy: 0.0440 - binary_accuracy: 0.9109\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2186 - accuracy: 0.0415 - binary_accuracy: 0.9089\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2153 - accuracy: 0.0453 - binary_accuracy: 0.9109\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2149 - accuracy: 0.0427 - binary_accuracy: 0.9108\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2159 - accuracy: 0.0443 - binary_accuracy: 0.9098\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2121 - accuracy: 0.0358 - binary_accuracy: 0.9121\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2166 - accuracy: 0.0464 - binary_accuracy: 0.9091\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.2132 - accuracy: 0.0551 - binary_accuracy: 0.9110\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2091 - accuracy: 0.0389 - binary_accuracy: 0.9130\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2094 - accuracy: 0.0402 - binary_accuracy: 0.9129\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2145 - accuracy: 0.0433 - binary_accuracy: 0.9105\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2109 - accuracy: 0.0453 - binary_accuracy: 0.9131\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2108 - accuracy: 0.0452 - binary_accuracy: 0.9134\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2108 - accuracy: 0.0426 - binary_accuracy: 0.9121\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.2121 - accuracy: 0.0434 - binary_accuracy: 0.9116\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.2095 - accuracy: 0.0455 - binary_accuracy: 0.9131\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2079 - accuracy: 0.0417 - binary_accuracy: 0.9138\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2070 - accuracy: 0.0415 - binary_accuracy: 0.9138\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2040 - accuracy: 0.0520 - binary_accuracy: 0.9158\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2067 - accuracy: 0.0457 - binary_accuracy: 0.9140\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2071 - accuracy: 0.0430 - binary_accuracy: 0.9137\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2054 - accuracy: 0.0449 - binary_accuracy: 0.9147\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2066 - accuracy: 0.0417 - binary_accuracy: 0.9146\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2030 - accuracy: 0.0429 - binary_accuracy: 0.9163\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2014 - accuracy: 0.0431 - binary_accuracy: 0.9171\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2031 - accuracy: 0.0437 - binary_accuracy: 0.9156\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2004 - accuracy: 0.0473 - binary_accuracy: 0.9175\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2029 - accuracy: 0.0529 - binary_accuracy: 0.9164\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2008 - accuracy: 0.0511 - binary_accuracy: 0.9167\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.2023 - accuracy: 0.0444 - binary_accuracy: 0.9166\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.2002 - accuracy: 0.0472 - binary_accuracy: 0.9176\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2017 - accuracy: 0.0557 - binary_accuracy: 0.9170\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1985 - accuracy: 0.0440 - binary_accuracy: 0.9178\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1992 - accuracy: 0.0562 - binary_accuracy: 0.9181\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2025 - accuracy: 0.0487 - binary_accuracy: 0.9157\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1974 - accuracy: 0.0498 - binary_accuracy: 0.9186\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2024 - accuracy: 0.0473 - binary_accuracy: 0.9163\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.1991 - accuracy: 0.0504 - binary_accuracy: 0.9181\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/32 [===============>..............] - ETA: 0s - loss: 0.5048 - accuracy: 0.0243 - binary_accuracy: 0.8251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 19:59:27.569484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5133 - accuracy: 0.0260 - binary_accuracy: 0.8233\n",
      "Loss: 0.5132701992988586\n",
      "Binary accuracy: 0.8233281373977661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5132701992988586, 0.026000000536441803, 0.8233281373977661)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Visualise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a56735fbaa4548a8f11f8a135804a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=199, step=5), Checkbox(value=False, description="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.generate_plots(n, model=None, x=None, y=None, target=True, prediction=True, raw_prediction=True, diff=True)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html\n",
    "interact(\n",
    "    generate_plots,\n",
    "    model = fixed(model),\n",
    "    x = fixed(X_test),\n",
    "    y = fixed(Y_test),\n",
    "    n=widgets.IntSlider(min=0, max=199, step=5, value=0),\n",
    "    target=False,\n",
    "    prediction=False,\n",
    "    raw_prediction=False,\n",
    "    diff=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this model performs approximately on par with the original fully connected network, we can see dramatic improvments in the ability to handle the motion of \"long range\" pieces - the model now has the ability to learn about which pieces can move in which axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
